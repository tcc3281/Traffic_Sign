{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.679905Z",
     "start_time": "2025-03-26T06:50:10.424903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "id": "64ada251d82fc2b3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.680905300Z",
     "start_time": "2025-03-26T06:50:17.678534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 15"
   ],
   "id": "9093b146809407b8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Loading and Processing Data",
   "id": "df851ac6c299ca7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.681905Z",
     "start_time": "2025-03-26T06:50:18.217195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRAIN_PATH='/kaggle/input/traffic-signs/dataset/train'\n",
    "# VAL_PATH='/kaggle/input/traffic-signs/dataset/val'\n",
    "# TEST_PATH='/kaggle/input/traffic-signs/dataset/test'\n",
    "# CLASS_MAPPING_PATH='/kaggle/input/traffic-signs/dataset/class_mapping.txt'\n",
    "TRAIN_PATH='../dataset/classification/train'\n",
    "VAL_PATH='../dataset/classification/val'\n",
    "TEST_PATH='../dataset/classification/test'\n",
    "CLASS_MAPPING_PATH='../dataset/classification/class_mapping.txt'"
   ],
   "id": "9682d1e7bced1cde",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.681905Z",
     "start_time": "2025-03-26T06:50:18.239276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hàm đọc class mapping từ file txt\n",
    "def load_class_mapping(txt_path):\n",
    "    idx_to_class = {}\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            idx, class_name = line.strip().split(':')\n",
    "            idx_to_class[int(idx)] = class_name.strip()\n",
    "    return idx_to_class\n",
    "\n",
    "# Load mapping\n",
    "idx_to_class = load_class_mapping(CLASS_MAPPING_PATH)\n",
    "class_to_idx = {v: k for k, v in idx_to_class.items()}  # Đảo ngược để có class_to_idx"
   ],
   "id": "7bc3e6f32d0f12b0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.681905Z",
     "start_time": "2025-03-26T06:50:18.265373Z"
    }
   },
   "cell_type": "code",
   "source": "class_to_idx",
   "id": "d1541f52fe49a603",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speed limit 20': 0,\n",
       " 'speed limit 30': 1,\n",
       " 'speed limit 50': 2,\n",
       " 'speed limit 60': 3,\n",
       " 'speed limit 70': 4,\n",
       " 'speed limit 80': 5,\n",
       " 'no entry for all vehicles': 6,\n",
       " 'speed limit 100': 7,\n",
       " 'speed limit 120': 8,\n",
       " 'no passing': 9,\n",
       " 'no truck passing': 10,\n",
       " 'no parking': 11,\n",
       " 'no horn': 12,\n",
       " 'no entry in this direction': 13,\n",
       " 'no cars': 14}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.682903400Z",
     "start_time": "2025-03-26T06:50:18.317430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder(TRAIN_PATH, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(VAL_PATH, transform=val_transform)\n",
    "test_dataset = datasets.ImageFolder(TEST_PATH, transform=test_transform)"
   ],
   "id": "1843f9ba4bcd11ac",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.682903400Z",
     "start_time": "2025-03-26T06:50:18.718762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ghi đè class names bằng mapping từ file\n",
    "train_dataset.classes = [idx_to_class[i] for i in sorted(idx_to_class.keys())]\n",
    "train_dataset.class_to_idx = {cls: i for i, cls in enumerate(train_dataset.classes)}\n",
    "\n",
    "# Ghi đè class names bằng mapping từ file\n",
    "val_dataset.classes = [idx_to_class[i] for i in sorted(idx_to_class.keys())]\n",
    "val_dataset.class_to_idx = {cls: i for i, cls in enumerate(val_dataset.classes)}\n",
    "\n",
    "# Ghi đè class names bằng mapping từ file\n",
    "test_dataset.classes = [idx_to_class[i] for i in sorted(idx_to_class.keys())]\n",
    "test_dataset.class_to_idx = {cls: i for i, cls in enumerate(test_dataset.classes)}\n",
    "\n",
    "# Tạo DataLoader (giữ nguyên)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "821ffd027699f1a4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:07.672005Z",
     "start_time": "2025-03-26T09:00:07.588953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train classes:\", train_dataset.classes)\n",
    "print(\"Class to index mapping:\", train_dataset.class_to_idx)"
   ],
   "id": "84473015834b1f9d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTrain classes:\u001B[39m\u001B[33m\"\u001B[39m, \u001B[43mtrain_dataset\u001B[49m.classes)\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mClass to index mapping:\u001B[39m\u001B[33m\"\u001B[39m, train_dataset.class_to_idx)\n",
      "\u001B[31mNameError\u001B[39m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Model",
   "id": "da7f7bb1fdb278d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:00:06.659876Z",
     "start_time": "2025-03-26T09:00:06.275752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load train model pth\n",
    "model_path='../model/resnet50_model_v01.pth'\n",
    "def load_model(model_path):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "model=load_model(model_path)"
   ],
   "id": "1d378f68faf89420",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m     model.load_state_dict(torch.load(model_path))\n\u001B[32m      7\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m model=\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mload_model\u001B[39m\u001B[34m(model_path)\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_model\u001B[39m(model_path):\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     model = \u001B[43mmodels\u001B[49m.resnet50(pretrained=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m      5\u001B[39m     model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n\u001B[32m      6\u001B[39m     model.load_state_dict(torch.load(model_path))\n",
      "\u001B[31mNameError\u001B[39m: name 'models' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T03:56:43.816942Z",
     "start_time": "2025-03-26T03:56:42.751306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Đóng băng tất cả trừ layer3, layer4 và fc\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer3\" not in name and \"layer4\" not in name and \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Thay đổi lớp FC cuối cho 15 lớp\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)"
   ],
   "id": "8b3f4d3c06642a64",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\chientuhocai\\Traffic_Sign\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\chientuhocai\\Traffic_Sign\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T03:56:43.882342Z",
     "start_time": "2025-03-26T03:56:43.873328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chuyển model sang GPU (nếu có)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "id": "649bde7ed59779d7",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T03:56:43.940255Z",
     "start_time": "2025-03-26T03:56:43.934649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)"
   ],
   "id": "d9b14ff2f90506f8",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T03:56:43.990067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lists để lưu metrics\n",
    "epochs_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # === Training Phase với Progress Bar ===\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n",
    "    for inputs, labels in train_loop:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_loop.set_postfix(loss=loss.item())  # Hiển thị loss hiện tại\n",
    "    \n",
    "    # === Validation Phase với Progress Bar ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loop:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_loop.set_postfix(val_loss=loss.item())  # Hiển thị val_loss hiện tại\n",
    "    \n",
    "    # === Tính toán metrics ===\n",
    "    train_loss /= len(train_dataset)\n",
    "    val_loss /= len(val_dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # Lưu metrics\n",
    "    epochs_list.append(epoch + 1)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    \n",
    "    # In thông tin epoch\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Accuracy: {accuracy:.4f} | \"\n",
    "          f\"Precision: {precision:.4f} | \"\n",
    "          f\"Recall: {recall:.4f}\")"
   ],
   "id": "8fe04f68c84bbf23",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Train]:  20%|█▉        | 326/1641 [22:23<1:28:13,  4.03s/it, loss=1.34] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"resnet50_model.pth\")    ",
   "id": "fa9244cf30284504",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_list, train_loss_list, label='Train Loss')\n",
    "plt.plot(epochs_list, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Metrics\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_list, accuracy_list, label='Accuracy')\n",
    "plt.plot(epochs_list, precision_list, label='Precision (Macro)')\n",
    "plt.plot(epochs_list, recall_list, label='Recall (Macro)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bb2bcbcebe20fab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Epoch': epochs_list,\n",
    "    'Train Loss': train_loss_list,\n",
    "    'Val Loss': val_loss_list,\n",
    "    'Accuracy': accuracy_list,\n",
    "    'Precision': precision_list,\n",
    "    'Recall': recall_list\n",
    "})\n",
    "\n",
    "metrics_df.to_csv('training_metrics.csv', index=False)"
   ],
   "id": "6b3b24bccc07dfa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T06:36:09.424767Z",
     "start_time": "2025-03-26T06:36:09.409383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create class mapping txt\n",
    "class_list=[\n",
    "    'speed limit 20',\n",
    "    'speed limit 30',\n",
    "    'speed limit 50',\n",
    "    'speed limit 60',\n",
    "    'speed limit 70',\n",
    "    'speed limit 80',\n",
    "    'no entry for all vehicles',\n",
    "    'speed limit 100',\n",
    "    'speed limit 120',\n",
    "    'no passing',\n",
    "    'no truck passing',\n",
    "    'no parking',\n",
    "    'no horn',\n",
    "    'no entry in this direction',\n",
    "    'no cars'\n",
    "]\n",
    "\n",
    "with open('class_mapping.txt', 'w') as file:\n",
    "    for i, class_name in enumerate(class_list):\n",
    "        file.write(f\"{i}: {class_name}\\n\")"
   ],
   "id": "b5a766a7ef457659",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1229331e2047b17a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
